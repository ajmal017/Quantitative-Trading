{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import datetime\n",
    "import modelling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tickers = ['XLF', 'XLK', 'XLE', 'XRT']\n",
    "path = r'C:\\Users\\JD\\Google Drive\\Quantitative Trading\\Data'\n",
    "dfs = [pd.read_csv(os.path.join(path, ticker + '.csv'), index_col=0, parse_dates=[0], dayfirst=True) for ticker in tickers]\n",
    "for ticker, df in zip(tickers, dfs):\n",
    "    df.columns = [ticker + ' ' + col for col in df.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = modelling.aggregate(dfs)\n",
    "datasetClean = dataset.dropna()\n",
    "datasetClean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetClean.plot(y=[ticker + ' Adj Close' for ticker in tickers])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Derive mean return:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetCopy = datasetClean.copy()\n",
    "adjClsCols = [ticker + ' Adj Close' for ticker in tickers]\n",
    "logRetCols = [ticker + ' Log Ret' for ticker in tickers]\n",
    "for logRetCol, adjClsCol in zip(logRetCols, adjClsCols):\n",
    "    datasetCopy[logRetCol] = np.log(datasetCopy[adjClsCol].pct_change(1) + 1)\n",
    "datasetCopy['Mean Log Ret'] = datasetCopy[logRetCols].mean(axis=1)\n",
    "datasetCopy = datasetCopy.dropna()\n",
    "datasetCopy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain excess returns through demeaning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xcessRetCols = [ticker + ' Excess Log Ret' for ticker in tickers]\n",
    "for xcessRetCol, logRetCol in zip(xcessRetCols, logRetCols):\n",
    "    datasetCopy[xcessRetCol] = datasetCopy[logRetCol] - datasetCopy['Mean Log Ret']\n",
    "datasetCopy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Derive weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetCopy['Sum Excess Log Rets'] = datasetCopy[xcessRetCols].abs().sum(axis=1)\n",
    "weightCols = [ticker + ' Weight' for ticker in tickers]\n",
    "for weightCol, xcessRetCol in zip(weightCols, xcessRetCols):\n",
    "    datasetCopy[weightCol] = datasetCopy[xcessRetCol] / datasetCopy['Sum Excess Log Rets']\n",
    "datasetCopy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "initialCapital = 10000\n",
    "clsCols = [ticker + ' Close' for ticker in tickers]\n",
    "allocationCols = [ticker + ' Allocated' for ticker in tickers]\n",
    "capitalUsedCols = [ticker + ' Positions To Take' for ticker in tickers]\n",
    "cashLeftCol = 'Cash Left'\n",
    "navCol = 'NAV'\n",
    "\n",
    "datasetCopy[navCol] = initialCapital\n",
    "datasetCopy[cashLeftCol] = 0\n",
    "for idx in datasetCopy.index:\n",
    "    for allocationCol, capitalUsedCol, clsCol, weightCol in zip(allocationCols, capitalUsedCols, clsCols, weightCols):\n",
    "        datasetCopy.loc[idx, allocationCol] = datasetCopy.loc[idx, navCol] * datasetCopy.loc[idx, weightCol]\n",
    "        datasetCopy.loc[idx, capitalUsedCol] = datasetCopy.loc[idx, allocationCol] // datasetCopy.loc[idx, clsCol]\n",
    "        \n",
    "        if idx == datasetCopy.index[0]:\n",
    "            datasetCopy.loc[idx, cashLeftCol] += datasetCopy.loc[idx, allocationCol] - datasetCopy.loc[idx, capitalUsedCol]\n",
    "        else:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
